# -*- coding: utf-8 -*-
"""ML ENSAMBLE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pC4V-5WqAu3hli_-ZZ0nR_jUymairoDU
"""



# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter

# Install torchinfo
!pip install torchinfo

# Import torchinfo
from torchinfo import summary

# If using Google Colab, mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Load your dataset
train_challenges_path = '/content/drive/MyDrive/2024-2/ARC/ARCmain/dataset/arc-agi_training_challenges.json'
test_challenges_path = '/content/drive/MyDrive/2024-2/ARC/ARCmain/dataset/arc-agi_test_challenges.json'
sample_submission_path = '/content/drive/MyDrive/2024-2/ARC/ARCmain/dataset/sample_submission.json'

with open(train_challenges_path, 'r') as f:
    train_challenges = json.load(f)

train_ids = list(train_challenges.keys())

# Check device configuration
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {DEVICE}')

# Initialize TensorBoard writer
writer = SummaryWriter('runs/ARC_experiment')

# ============================
# 1. Define the Custom Dataset
# ============================

class CustomGridDataset(Dataset):
    """
    Custom dataset for ARC tasks.
    Each sample consists of an input grid and a target grid.
    """
    def __init__(self, challenges, ids, max_size=(30, 30)):
        self.challenges = challenges
        self.ids = ids
        self.max_size = max_size  # Maximum grid size (H, W)

        # Collect all input-output pairs from all tasks
        self.samples = []
        for id in self.ids:
            task = self.challenges[id]
            for sample in task['train']:
                self.samples.append((sample['input'], sample['output']))

    def __len__(self):
        return len(self.samples)

    def pad_grid(self, grid):
        """Pad the grid to the maximum size with a special value (e.g., 255)."""
        grid = np.array(grid)
        H, W = grid.shape
        max_H, max_W = self.max_size
        padded_grid = np.full((max_H, max_W), 255, dtype=np.int64)  # Use 255 as padding value
        padded_grid[:H, :W] = grid
        return padded_grid

    def __getitem__(self, idx):
        input_grid, target_grid = self.samples[idx]

        # Pad grids to the maximum size
        input_grid = self.pad_grid(input_grid)
        target_grid = self.pad_grid(target_grid)

        # Convert to tensors
        input_grid = torch.tensor(input_grid, dtype=torch.float)
        target_grid = torch.tensor(target_grid, dtype=torch.long)

        # Set padding values to 0 in input grid
        input_grid[input_grid == 255] = 0.0

        # Normalize input grid
        input_grid = input_grid / 9.0  # Assuming colors range from 0 to 9

        # Ensure grids have shape (C=1, H, W)
        input_grid = input_grid.unsqueeze(0)
        target_grid = target_grid.unsqueeze(0)

        return input_grid, target_grid

# Instantiate the dataset and dataloader
train_dataset = CustomGridDataset(train_challenges, train_ids, max_size=(30, 30))

def collate_fn(batch):
    inputs, targets = zip(*batch)  # Each is a tuple of tensors
    inputs = torch.stack(inputs)
    targets = torch.stack(targets)
    return inputs, targets

train_loader = DataLoader(
    train_dataset,
    batch_size=16,
    shuffle=True,
    num_workers=2,
    collate_fn=collate_fn
)

# =====================================
# 2. Define Model Components
# =====================================

# 2.1 CNN Feature Extractor
class CNNFeatureExtractor(nn.Module):
    def __init__(self, input_channels=1, embed_size=64):
        super(CNNFeatureExtractor, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, embed_size, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(embed_size)
        )

    def forward(self, x):
        x = self.conv_layers(x)  # (Batch, embed_size, H, W)
        return x

# 2.2 Autoencoder Encoder
class AutoencoderEncoder(nn.Module):
    def __init__(self, embed_size=64, latent_dim=128):
        super(AutoencoderEncoder, self).__init__()
        self.fc = nn.Linear(embed_size * 30 * 30, latent_dim)

    def forward(self, x):
        batch_size = x.size(0)
        x = x.view(batch_size, -1)
        latent = self.fc(x)
        return latent

# 2.3 Multi-Layer LSTM
class MultiLayerLSTM(nn.Module):
    def __init__(self, input_size=128, hidden_size=128, num_layers=2, dropout=0.1):
        super(MultiLayerLSTM, self).__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )

    def forward(self, x):
        x = x.unsqueeze(1)  # (Batch, Seq_len=1, input_size)
        lstm_out, _ = self.lstm(x)
        lstm_out = lstm_out.squeeze(1)  # (Batch, hidden_size)
        return lstm_out

# 2.4 Autoencoder Decoder
class AutoencoderDecoder(nn.Module):
    def __init__(self, latent_dim=128, embed_size=64, output_channels=10):
        super(AutoencoderDecoder, self).__init__()
        self.fc = nn.Linear(latent_dim, embed_size * 30 * 30)
        self.conv_layers = nn.Sequential(
            nn.ConvTranspose2d(embed_size, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.ConvTranspose2d(32, output_channels, kernel_size=3, padding=1)
        )

    def forward(self, x):
        batch_size = x.size(0)
        x = self.fc(x)
        x = x.view(batch_size, -1, 30, 30)
        x = self.conv_layers(x)
        return x  # (Batch, output_channels, H, W)

# 2.5 Combined Model
class CombinedModel(nn.Module):
    def __init__(
        self,
        input_channels=1,
        embed_size=64,
        latent_dim=128,
        hidden_size=128,
        output_channels=10,
        num_lstm_layers=2,
        dropout=0.1
    ):
        super(CombinedModel, self).__init__()
        self.feature_extractor = CNNFeatureExtractor(input_channels, embed_size)
        self.encoder = AutoencoderEncoder(embed_size, latent_dim)
        self.lstm = MultiLayerLSTM(latent_dim, hidden_size, num_lstm_layers, dropout)
        self.decoder = AutoencoderDecoder(hidden_size, embed_size, output_channels)

    def forward(self, x):
        features = self.feature_extractor(x)
        latent = self.encoder(features)
        lstm_output = self.lstm(latent)
        output = self.decoder(lstm_output)
        return output  # (Batch, output_channels, H, W)

# =====================================
# 3. Define the Training Class
# =====================================

class Training:
    def __init__(self, model, train_loader, criterion, optimizer, device, writer, loss_threshold=100):
        self.model = model
        self.train_loader = train_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.loss_threshold = loss_threshold
        self.writer = writer  # TensorBoard writer

    def train_model(self, num_epochs=32, patience=20, save_path='best_model.pth'):
        history = {'train_loss': []}
        best_loss = self.loss_threshold
        patience_counter = 0

        global_step = 0  # For TensorBoard

        for epoch in range(1, num_epochs + 1):
            self.model.train()
            epoch_loss = 0.0

            for batch_idx, (inputs, targets) in enumerate(self.train_loader):
                inputs = inputs.to(self.device)
                targets = targets.to(self.device)

                # Forward pass
                outputs = self.model(inputs)  # Outputs: (Batch, output_channels, H, W)
                outputs = outputs.view(-1, outputs.shape[1])  # Flatten to (N, output_channels)
                targets_flat = targets.view(-1)  # Flatten to (N)

                # Compute loss
                loss = self.criterion(outputs, targets_flat)

                # Backward pass and optimization
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

                epoch_loss += loss.item()

                # Write to TensorBoard
                self.writer.add_scalar('Loss/train', loss.item(), global_step)
                global_step += 1

                if (batch_idx + 1) % 10 == 0:
                    print(f'Epoch [{epoch}], Step [{batch_idx + 1}/{len(self.train_loader)}], Loss: {loss.item():.4f}')

            average_loss = epoch_loss / len(self.train_loader)
            print(f'Epoch [{epoch}] Average Loss: {average_loss:.4f}')

            history['train_loss'].append(average_loss)

            # Write average loss to TensorBoard
            self.writer.add_scalar('Loss/epoch', average_loss, epoch)

            # Check for improvement
            if average_loss < best_loss:
                best_loss = average_loss
                torch.save(self.model.state_dict(), save_path)
                print(f'New best model saved with loss: {best_loss:.4f}')
                patience_counter = 0
            else:
                patience_counter += 1
                print(f'No improvement in loss for {patience_counter} epoch(s).')
                if patience_counter >= patience:
                    print('Early stopping triggered.')
                    break

        # Plot training loss
        plt.figure(figsize=(10, 5))
        plt.plot(history['train_loss'], 'o-', label='Training Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training Loss Over Epochs')
        plt.legend()
        plt.grid(True)
        plt.show()

        return history

# =====================================
# 4. Instantiate the Combined Model
# =====================================

input_channels = 1
output_channels = 10  # Number of color classes in ARC (0-9)
embed_size = 64
latent_dim = 128
hidden_size = 128

model = CombinedModel(
    input_channels=input_channels,
    embed_size=embed_size,
    latent_dim=latent_dim,
    hidden_size=hidden_size,
    output_channels=output_channels,
    num_lstm_layers=2,
    dropout=0.1
).to(DEVICE)

# Add model graph to TensorBoard
dummy_input = torch.zeros((1, 1, 30, 30)).to(DEVICE)
writer.add_graph(model, dummy_input)

# Print model summary using torchinfo
summary(model, input_size=(1, 1, 30, 30), device=DEVICE.type)

# =====================================
# 5. Define Loss Function and Optimizer
# =====================================

criterion = nn.CrossEntropyLoss(ignore_index=255)  # Ignore the padding value
optimizer = optim.Adam(model.parameters(), lr=0.001)

# =====================================
# 6. Initialize and Start Training
# =====================================

training = Training(
    model=model,
    train_loader=train_loader,
    criterion=criterion,
    optimizer=optimizer,
    device=DEVICE,
    writer=writer
)

training.train_model(num_epochs=32, patience=20, save_path='best_model.pth')

# Close the TensorBoard writer
writer.close()

# =====================================
# 7. Use the Trained Model for Submission
# =====================================

def preprocess_input(grid, max_size=(30, 30)):
    # Pad the grid to the maximum size
    grid = np.array(grid)
    H, W = grid.shape
    max_H, max_W = max_size
    padded_grid = np.full((max_H, max_W), 255, dtype=np.int64)
    padded_grid[:H, :W] = grid

    # Convert to tensor
    input_grid = torch.tensor(padded_grid, dtype=torch.float)

    # Set padding values to 0
    input_grid[input_grid == 255] = 0.0

    # Normalize
    input_grid = input_grid / 9.0

    # Add channel dimension
    input_grid = input_grid.unsqueeze(0)  # Shape: (1, H, W)

    # Add batch dimension
    input_grid = input_grid.unsqueeze(0)  # Shape: (1, 1, H, W)

    return input_grid

def set_submission():
    # Load sample submission and test data
    sample_submission_path = '/content/drive/MyDrive/2024-2/ARC/ARCmain/dataset/sample_submission.json'
    test_challenges_path = '/content/drive/MyDrive/2024-2/ARC/ARCmain/dataset/arc-agi_test_challenges.json'

    with open(sample_submission_path, 'r') as f:
        sample_sub = json.load(f)

    with open(test_challenges_path, 'r') as f:
        test_tasks = json.load(f)

    tasks_name = list(test_tasks.keys())
    tasks_file = list(test_tasks.values())

    # Load the trained model
    model.load_state_dict(torch.load('best_model.pth', map_location=DEVICE))
    model.eval()

    # Loop through test tasks
    for n, task in enumerate(tasks_file):
        for i in range(len(task['test'])):
            inp_test = task['test'][i]['input']
            # Preprocess input
            inp_test_tensor = preprocess_input(inp_test).to(DEVICE)

            with torch.no_grad():
                output = model(inp_test_tensor)  # Output shape: (1, output_channels, H, W)
                output = torch.argmax(output, dim=1).squeeze(0)  # Shape: (H, W)

                # Remove padding
                H, W = np.array(inp_test).shape
                output = output[:H, :W]

                answer_ = output.cpu().numpy().tolist()

                # Assign to submission
                sample_sub[tasks_name[n]][i]['attempt_1'] = answer_

    # Save submission
    with open('submission.json', 'w') as file:
        json.dump(sample_sub, file, indent=4)
    print("Submission file 'submission.json' created successfully.")

# Generate submission
set_submission()

# =====================================
# 8. Visualize Sample Inputs and Outputs
# =====================================

def visualize_sample(model, dataset, index):
    model.eval()
    input_grid, target_grid = dataset[index]
    input_grid = input_grid.unsqueeze(0).to(DEVICE)  # Add batch dimension
    with torch.no_grad():
        output = model(input_grid)
        output = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

    # Remove padding
    H, W = (target_grid[0] != 255).nonzero(as_tuple=True)
    if len(H) > 0 and len(W) > 0:
        max_H = H.max().item() + 1
        max_W = W.max().item() + 1
    else:
        max_H, max_W = target_grid.shape[1:]

    output = output[:max_H, :max_W]
    input_grid = input_grid.squeeze(0).cpu().numpy()[0, :max_H, :max_W]
    target_grid = target_grid.numpy()[0, :max_H, :max_W]

    # Plotting
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(input_grid, cmap='tab20', vmin=0, vmax=1)
    axs[0].set_title('Input Grid')
    axs[1].imshow(target_grid, cmap='tab20', vmin=0, vmax=9)
    axs[1].set_title('Target Grid')
    axs[2].imshow(output, cmap='tab20', vmin=0, vmax=9)
    axs[2].set_title('Model Output')
    plt.show()

# Visualize a sample
visualize_sample(model, train_dataset, index=0)

from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments
import torch
from torch.utils.data import Dataset

# Custom Dataset class for our 2D grid task
class GridDataset(Dataset):
    def __init__(self, input_grids, output_grids):
        self.inputs = input_grids
        self.outputs = output_grids

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        return {"input_ids": torch.tensor(self.inputs[idx], dtype=torch.long),
                "labels": torch.tensor(self.outputs[idx], dtype=torch.long)}

# Tokenizer and Model initialization
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

# Sample Training Data
train_input = [
    [0, 1, 0, 0, 0, 0, 0, 1, 0], # Flattened input grid 1
    [0, 0, 0, 1, 0, 0, 0, 0, 0], # Flattened input grid 2
    # Add more flattened inputs as needed
]

train_output = [
    [2, 0, 0, 0, 0, 0, 0, 0, 0], # Flattened output grid 1
    [2, 2, 0, 0, 0, 0, 0, 0, 0], # Flattened output grid 2
    # Add more flattened outputs as needed
]

# Create Dataset
train_dataset = GridDataset(train_input, train_output)

# Define Training Arguments
training_args = TrainingArguments(
    output_dir="./gpt2-grid-output",
    evaluation_strategy="steps",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    save_steps=10_000,
    save_total_limit=2,
    logging_dir="./logs",
)

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
)

# Fine-tune the GPT-2 model
trainer.train()

# Sample Training Data
train_input = [
    [0, 1, 0, 0, 0, 0, 0, 1, 0], # Flattened input grid 1
    [0, 0, 0, 1, 0, 0, 0, 0, 0], # Flattened input grid 2
    # Add more flattened inputs as needed
]

train_output = [
    [2, 0, 0, 0, 0, 0, 0, 0, 0], # Flattened output grid 1
    [2, 2, 0, 0, 0, 0, 0, 0, 0], # Flattened output grid 2
    # Add more flattened outputs as needed
]

# Create Dataset
train_dataset = GridDataset(train_input, train_output)

# Define Training Arguments
training_args = TrainingArguments(
    output_dir="./gpt2-grid-output",
    evaluation_strategy="steps",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    save_steps=10_000,
    save_total_limit=2,
    logging_dir="./logs",
)

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
)

# Fine-tune the GPT-2 model
trainer.train()