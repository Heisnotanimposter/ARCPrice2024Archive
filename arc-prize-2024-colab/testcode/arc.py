# -*- coding: utf-8 -*-
"""ARC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uuFjx6oMX8xx_wTmFhuqbHJPqlKxziY7
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install colorama
!pip install utils
!pip install xLSTM

# Commented out IPython magic to ensure Python compatibility.
import time

import os, gc
import sys, pdb
import copy, time
import json, random

import itertools
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
from pathlib import Path

import matplotlib
from matplotlib import colors
import matplotlib.pyplot as plt
#from utils import plot_pic

from colorama import Style, Fore
from tqdm import tqdm

# %matplotlib inline

import numpy as np
import json
import os
from tqdm import tqdm
import torch
from torch.utils.data import DataLoader
from xlstm.xlstm_lm_model import xLSTMLMModel, xLSTMLMModelConfig
from torch import nn, optim
from torch.utils.data import Dataset
!CUDA_HOME='/usr/local/cuda'

!ls /content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/

train1_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/arc-agi_training_challenges.json'

train2_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/arc-agi_training_solutions.json'

visual_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/visualization/'

eval1_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/arc-agi_evaluation_challenges.json'

eval2_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/arc-agi_evaluation_solutions.json'

test_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/arc-agi_test_challenges.json'

sample_path = '/content/drive/MyDrive/2024-2/ARC/ARCPrice2024/arc-prize-2024-colab/sample_submission.json'

cmap = colors.ListedColormap(
    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',
     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])

norm = colors.Normalize(vmin=0, vmax=9)
color_list = ["black", "blue", "red", "green", "yellow", "gray", "magenta", "orange", "sky", "brown"]

def load_and_preprocess_arc_data(challenges_path, solutions_path, save_path):
    with open(challenges_path, 'r') as f:
        challenges_data = json.load(f)
    with open(solutions_path, 'r') as f:
        solutions_data = json.load(f)

    os.makedirs(save_path, exist_ok=True)

    inputs, outputs = [], []

    for task_id, task_data in tqdm(challenges_data.items(), desc="Processing tasks"):
        for i, (train_example, test_example) in enumerate(zip(task_data["train"], task_data["test"])):
            train_input = np.array(train_example["input"])
            train_output = np.array(train_example["output"])
            test_input = np.array(test_example["input"])

            # Normalize and flatten the inputs
            train_input_normalized = train_input.flatten() / 9.0
            train_output_normalized = train_output.flatten() / 9.0
            test_input_normalized = test_input.flatten() / 9.0

            # Append to dataset
            inputs.append(train_input_normalized)
            outputs.append(train_output_normalized)

    return np.array(inputs), np.array(outputs)

class ARCDataset(Dataset):
    def __init__(self, inputs, outputs):
        self.inputs = torch.tensor(inputs, dtype=torch.float32)
        self.outputs = torch.tensor(outputs, dtype=torch.float32)

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        return self.inputs[idx], self.outputs[idx]

inputs, outputs = load_and_preprocess_arc_data(train1_path, train2_path, save_path='visualization/')
dataset = ARCDataset(inputs, outputs)
train_loader = DataLoader(dataset, batch_size=64, shuffle=True)

# Define xLSTM model
model_config = xLSTMLMModelConfig(
    input_size=100,  # Modify according to your input shape
    hidden_size=128,
    num_layers=2,
    output_size=100  # Adjust for output dimensions
)
model = xLSTMLMModel(model_config)

# Training setup
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train_xlstm(model, dataloader, optimizer, criterion, epochs=10):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}"):
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}")

# Train the model
train_xlstm(model, train_loader, optimizer, criterion)

# Commented out IPython magic to ensure Python compatibility.
# %cd $visual_path
!ls





