# -*- coding: utf-8 -*-
"""ARC With RNN 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/arc-with-rnn-3-7ea5dec3-2a9d-4d5f-bc8b-06c58ab64466.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241013/auto/storage/goog4_request%26X-Goog-Date%3D20241013T070747Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da16c2f5a4c96c1391a24fe1cb5589e5e4f519acffadcb1f87bb85d92de2ee8c8a5fa22fbc80007dfbf960b692d7168b9a57eb71fc5d0036f608c2da58cc7fd84e7a74ee2fed993b23dc38774075fdfa21ed14906cbb9ccd2f854554f246367232bcdc62d3e42a50476ae503342e12ed3cf7b1f3d8a6a77e1c7c9f5886ba7f9ec7cbd0b511528b9e62544247b8433fe2899199e33df56795aa3b38b7c3e4ac1e8fb7edaccd30c218c5951b9711a12d61a398163a4ab98628feba03f47ec124789634f46af9c0545fb56e4238484b65afa393d9d4e2dfcb5979cc7d92dcdf89bf27b54bc70e535a26328f86b97817ec19648ad6b01761c49abd92b1b1c31eaa53e
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'arc-prize-2024:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F67357%2F8951125%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241013%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241013T070747Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5e25327b3b845bd64a06f18adf2605ed5050c32265940add18b5fd01750e51e13f539db05ae1bdc12a12d379cd7053290574ce3de65d6c041a259a710ee3d6b475d5a4d1e55d730cf90a03934aab695131f9b05beec5efea6382bdb15c5bda59c8153344da9abf9014cac73a4e6d55a743465dc2c152b306bf81cd78edbf9485a78dfbb3fe34d8c1a6fbc15c30cc4e229073e4a4fb703d6992c0c299884667a486121a24c19dada30a8072c6a630b598c556e7bf6de4da696e8b1e4324c36303216bd4d14f90b909676f29eb481f96f0aceb59b1cefced3d3e862730871ddefeb3e564f95141f05aab71098de860a4e222ce2c5e052c097c1c5d3863b150ab20,arc-rnn:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5748424%2F9490460%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241013%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241013T070747Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9eb467eed9521493c51442fc5abf3e37c52c5ef5173ea18ebd993d3ed623c6f4fc75559984cd32d5818ad96948df2c2993eaf02634c3ebfcf68a942650d46444d0d18634759fe9f7caa5f50b43c2748e79c1a78bef4b13a066881fa1dc51dc6892652b1d08a03a25d7d0691d6ee068e93c5dbbf311c8d3de7f4472a8551956a423c1dc26b216b8faa8c1e65e9a107cb2a9671e58ee09928b8b21b9690caa590d0a5a3991ea1ee216444f557c5341e19491175e89b5f6137214a206ef479805eb388f5840e79154fff6fddeea538ccde0ac631d5b9402c0befca0882b7d5320e4a1f1893e6c2329b4e072c933dee4dd48e1f9cc10df5b91078683d277c6997a90'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""# ARC with RNN! - Shape Stable

<img src="https://www.kaggle.com/competitions/67357/images/header" alt="drawing" style="width:100%;"/>

### TODO
    Develop Higher-Depth Reasoning Process
    Determine Output Shape
    PixelVector = CONCAT(
      Pixels Located Relatively + Pixels Located Absolutely (363442ee, 63613498, aabf363d) +
      3 Pixels with point-symmetric and line-symmetric relationships (3631a71a, 68b16354)
    )

---

# Step 1: Setup

> ### Add Path
"""

import sys
sys.path.insert(1, '/kaggle/input/arc-rnn')
sys.path.insert(1, '/kaggle/input/arc-rnn/lib')

"""# Step 2. Load Config Files and Training Function"""

from omegaconf import OmegaConf
from train import train

base_path = '/kaggle/input/arc-prize-2024/'
config_path = '/kaggle/input/arc-rnn/configs/'

def load_config(path, config_path=config_path):
    return OmegaConf.load(config_path + path)

# Hyperparameters for Training
def load_default_train_config(ignore_color=False):
    config_data = load_config("data/PixelEachSubstitutor.yaml")
    config_lighthing = load_config("lightning/PixelEachSubstitutorRepeat.yaml")
    config_model = load_config("model/PixelEachSubstitutorRepeat.yaml")
    config_train = load_config("train/PixelEachSubstitutor.yaml")
    config_test = load_config("test/PixelEachSubstitutor.yaml")

    config_train = OmegaConf.merge({'data': config_data, 'lightning': config_lighthing, 'model': config_model, 'train': config_train, 'test': config_test})
    config_train.data.params.base_path = base_path

    return config_train

"""# Step 3: Train and Test Model

> ## Sample a few tasks
"""

from rich import print
from data import ARCDataset
from arc.constants import get_challenges_solutions_filepath
from arc.utils.visualize import plot_task
from classify import ARCDataClassifier


data_category = 'train'
challenges, solutions = get_challenges_solutions_filepath(data_category, base_path)

tasks_sequential_simple_line = '''\
d9f24cd1 3bd67248 5c0a986e *7ddcd7ec'''

def filter_data_codes(data_codes: list[str]):
    return tuple(filter(lambda x: len(x) == 8, data_codes.split()))


# Filtering Dataset
filter_funcs = (
#     ARCDataClassifier.is_same_shape_f(True),
    ARCDataClassifier.in_data_codes_f([
        *filter_data_codes(tasks_sequential_simple_line),
    ], reorder=True),
)

dataset = ARCDataset(challenges, solutions, one_hot=False, filter_funcs=filter_funcs)
print(f'Data size: {len(dataset)}')

# Visualize a task
# for index in range(len(dataset)):
#     plot_task(dataset, index, data_category)
#     break

"""> ## Main Function (Sample)"""

# config = load_default_train_config()
# config.lightning.params.n_trials = 1 # Default: 2
# model = train(config, filter_funcs=filter_funcs, test=False)

"""> ## Main Function"""

config = load_default_train_config()
config.lightning.params.n_trials = 1 # Default: 2
model = train(config, test=True)

"""# Step 4: See Test Results"""

# from arc.utils.visualize import plot_xytc_from_json

# file_path = './test_results.json'
# plot_xytc_from_json(file_path, plot_only_correct=False, top_k=2, total=100)